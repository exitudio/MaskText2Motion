{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('../')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import join as pjoin\n",
    "from torch.distributions import Categorical\n",
    "import json\n",
    "import clip\n",
    "\n",
    "import options.option_transformer as option_trans\n",
    "import models.vqvae as vqvae\n",
    "import utils.utils_model as utils_model\n",
    "import utils.eval_trans as eval_trans\n",
    "from dataset import dataset_TM_train\n",
    "from dataset import dataset_TM_eval\n",
    "from dataset import dataset_tokenize\n",
    "import models.t2m_trans as trans\n",
    "from options.get_eval_option import get_opt\n",
    "from models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mock:: opt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4888/4888 [00:01<00:00, 3344.22it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 2869.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer Pointing at 0\n",
      "Reading checkpoints/kit/Comp_v6_KLD005/opt.txt\n",
      "Loading Evaluation Model Wrapper (Epoch 30) Completed!!\n"
     ]
    }
   ],
   "source": [
    "class Temp:\n",
    "    def __init__(self):\n",
    "        print('mock:: opt')\n",
    "args = Temp()\n",
    "args.dataname = args.dataset_name = 'kit'\n",
    "args.down_t = 2\n",
    "\n",
    "train_loader_token = dataset_tokenize.DATALoader(args.dataname, 1, unit_length=2**args.down_t)\n",
    "\n",
    "from utils.word_vectorizer import WordVectorizer\n",
    "w_vectorizer = WordVectorizer('./glove', 'our_vab')\n",
    "val_loader = dataset_TM_eval.DATALoader(args.dataname, False, 32, w_vectorizer)\n",
    "\n",
    "dataset_opt_path = 'checkpoints/kit/Comp_v6_KLD005/opt.txt' if args.dataname == 'kit' else 'checkpoints/t2m/Comp_v6_KLD005/opt.txt'\n",
    "\n",
    "wrapper_opt = get_opt(dataset_opt_path, torch.device('cuda'))\n",
    "eval_wrapper = EvaluatorModelWrapper(wrapper_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ---- Network ---- #####\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=torch.device('cuda'), jit=False)  # Must set jit=False for training\n",
    "clip.model.convert_weights(clip_model)  # Actually this line is unnecessary since clip by default already on float16\n",
    "clip_model.eval()\n",
    "for p in clip_model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.nb_code = 512 # 8192 # \n",
    "args.code_dim = 512 # 32 # \n",
    "args.output_emb_width = 512\n",
    "args.down_t = 2\n",
    "args.stride_t = 2\n",
    "args.width = 512\n",
    "args.depth = 3\n",
    "args.dilation_growth_rate = 3\n",
    "args.vq_act = 'relu'\n",
    "args.vq_norm = None\n",
    "args.quantizer = 'ema_reset'\n",
    "args.mu = 0.99\n",
    "\n",
    "net = vqvae.HumanVQVAE(args, ## use args to define different parameters in different quantizers\n",
    "                       args.nb_code,\n",
    "                       args.code_dim,\n",
    "                       args.output_emb_width,\n",
    "                       args.down_t,\n",
    "                       args.stride_t,\n",
    "                       args.width,\n",
    "                       args.depth,\n",
    "                       args.dilation_growth_rate)\n",
    "args.embed_dim_gpt = 1024\n",
    "args.clip_dim = 512\n",
    "args.block_size = 51\n",
    "args.num_layers = 9\n",
    "args.n_head_gpt = 16\n",
    "args.drop_out_rate = 0.1\n",
    "args.ff_rate = 4\n",
    "trans_encoder = trans.Text2Motion_Transformer(num_vq=args.nb_code, \n",
    "                                            embed_dim=args.embed_dim_gpt, \n",
    "                                            clip_dim=args.clip_dim, \n",
    "                                            block_size=args.block_size, \n",
    "                                            num_layers=args.num_layers, \n",
    "                                            n_head=args.n_head_gpt, \n",
    "                                            drop_out_rate=args.drop_out_rate, \n",
    "                                            fc_rate=args.ff_rate)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "trans_encoder.train()\n",
    "trans_encoder.cuda()\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose: torch.Size([1, 64, 251]) ('M00099',)\n",
      "pose: torch.Size([1, 160, 251]) ('03902',)\n",
      "pose: torch.Size([1, 84, 251]) ('M03783',)\n",
      "pose: torch.Size([1, 52, 251]) ('00913',)\n",
      "pose: torch.Size([1, 36, 251]) ('M00447',)\n",
      "pose: torch.Size([1, 64, 251]) ('02120',)\n",
      "pose: torch.Size([1, 80, 251]) ('02096',)\n",
      "pose: torch.Size([1, 52, 251]) ('M00984',)\n",
      "pose: torch.Size([1, 44, 251]) ('01254',)\n",
      "pose: torch.Size([1, 40, 251]) ('01839',)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for batch in train_loader_token:\n",
    "    pose, name = batch\n",
    "    bs, seq = pose.shape[0], pose.shape[1]\n",
    "\n",
    "    pose = pose.cuda().float() # bs, nb_joints, joints_dim, seq_len\n",
    "    target = net.encode(pose)\n",
    "    target = target.cpu().numpy()\n",
    "    print('pose:', pose.shape, name)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQVAE encoder index precomputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4888/4888 [00:01<00:00, 2713.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader_token = dataset_tokenize.DATALoader(args.dataname, 1, unit_length=2**args.down_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader_token:\n",
    "    pose, name = batch\n",
    "    bs, seq = pose.shape[0], pose.shape[1]\n",
    "\n",
    "    pose = pose.cuda().float() # bs, nb_joints, joints_dim, seq_len\n",
    "    target = net.encode(pose)\n",
    "    target = target.cpu().numpy()\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4888/4888 [00:01<00:00, 4241.61it/s]\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 2\n",
    "args.vq_name = 'VQVAE'\n",
    "train_loader = dataset_TM_train.DATALoader(args.dataname, args.batch_size, args.nb_code, args.vq_name, unit_length=2**args.down_t)\n",
    "train_loader_iter = dataset_TM_train.cycle(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.pkeep = .5\n",
    "batch = next(train_loader_iter)\n",
    "clip_text, m_tokens, m_tokens_len = batch\n",
    "m_tokens, m_tokens_len = m_tokens.cuda(), m_tokens_len.cuda()\n",
    "bs = m_tokens.shape[0]\n",
    "target = m_tokens    # (bs, 26)\n",
    "target = target.cuda()\n",
    "\n",
    "text = clip.tokenize(clip_text, truncate=True).cuda()\n",
    "    \n",
    "feat_clip_text = clip_model.encode_text(text).float()\n",
    "\n",
    "input_index = target[:,:-1]\n",
    "\n",
    "if args.pkeep == -1:\n",
    "    proba = np.random.rand(1)[0]\n",
    "    mask = torch.bernoulli(proba * torch.ones(input_index.shape,\n",
    "                                                        device=input_index.device))\n",
    "else:\n",
    "    mask = torch.bernoulli(args.pkeep * torch.ones(input_index.shape,\n",
    "                                                        device=input_index.device))\n",
    "mask = mask.round().to(dtype=torch.int64)\n",
    "r_indices = torch.randint_like(input_index, args.nb_code)\n",
    "a_indices = mask*input_index+(1-mask)*r_indices\n",
    "\n",
    "cls_pred = trans_encoder(a_indices, feat_clip_text)\n",
    "cls_pred = cls_pred.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.if_maxtest = False\n",
    "\n",
    "right_num = 0\n",
    "loss_ce = torch.nn.CrossEntropyLoss()\n",
    "loss_cls = 0.0\n",
    "for i in range(bs):\n",
    "    # loss function     (26), (26, 513)\n",
    "    loss_cls += loss_ce(cls_pred[i][:m_tokens_len[i] + 1], target[i][:m_tokens_len[i] + 1]) / bs\n",
    "\n",
    "    # Accuracy\n",
    "    probs = torch.softmax(cls_pred[i][:m_tokens_len[i] + 1], dim=-1)\n",
    "\n",
    "    if args.if_maxtest:\n",
    "        _, cls_pred_index = torch.max(probs, dim=-1)\n",
    "    else:\n",
    "        dist = Categorical(probs)\n",
    "        cls_pred_index = dist.sample()\n",
    "    right_num += (cls_pred_index.flatten(0) == target[i][:m_tokens_len[i] + 1].flatten(0)).sum().item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 2423.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer Pointing at 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loader = dataset_TM_eval.DATALoader(args.dataname, False, 32, w_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "./Test/FID fid nb_iter\n"
     ]
    }
   ],
   "source": [
    "class LoggerWriterMock:\n",
    "    def __init__(self):\n",
    "        self.info\n",
    "    def info(self, *args):\n",
    "        print(*args)\n",
    "    def add_scalar(self, *args):\n",
    "        print(*args)\n",
    "    def add_video(self, *args):\n",
    "        print(*args)\n",
    "logger = LoggerWriterMock()\n",
    "logger.info('test')\n",
    "writer = LoggerWriterMock()\n",
    "writer.add_scalar('./Test/FID', 'fid', 'nb_iter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose: torch.Size([32, 196, 251])\n",
      "index_motion: torch.Size([1, 50])\n",
      "pred_pose: torch.Size([1, 200, 251])\n",
      "pred_pose_eval: torch.Size([32, 196, 251])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Named, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradNestedTensor, UNKNOWN_TENSOR_TYPE_ID, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, Autocast, Batched, VmapMode].\n\nCPU: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/build/aten/src/ATen/RegisterCPU.cpp:5925 [kernel]\nCUDA: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/build/aten/src/ATen/RegisterCUDA.cpp:7100 [kernel]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/build/aten/src/ATen/RegisterQuantizedCPU.cpp:641 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradNestedTensor: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nTracer: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/TraceType_2.cpp:10525 [kernel]\nAutocast: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/autocast_mode.cpp:254 [kernel]\nBatched: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m args\u001b[39m.\u001b[39mout_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m best_fid, best_iter, best_div, best_top1, best_top2, best_top3, best_matching, writer, logger \u001b[39m=\u001b[39m \\\n\u001b[0;32m----> 3\u001b[0m     eval_trans\u001b[39m.\u001b[39;49mevaluation_transformer(args\u001b[39m.\u001b[39;49mout_dir, \n\u001b[1;32m      4\u001b[0m         val_loader, \n\u001b[1;32m      5\u001b[0m         net, \n\u001b[1;32m      6\u001b[0m         trans_encoder, \n\u001b[1;32m      7\u001b[0m         logger, \n\u001b[1;32m      8\u001b[0m         writer, \n\u001b[1;32m      9\u001b[0m         \u001b[39m0\u001b[39;49m, \n\u001b[1;32m     10\u001b[0m         best_fid\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, \n\u001b[1;32m     11\u001b[0m         best_iter\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \n\u001b[1;32m     12\u001b[0m         best_div\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m     13\u001b[0m         best_top1\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \n\u001b[1;32m     14\u001b[0m         best_top2\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \n\u001b[1;32m     15\u001b[0m         best_top3\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \n\u001b[1;32m     16\u001b[0m         best_matching\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m     17\u001b[0m         clip_model\u001b[39m=\u001b[39;49mclip_model, \n\u001b[1;32m     18\u001b[0m         eval_wrapper\u001b[39m=\u001b[39;49meval_wrapper)\n",
      "File \u001b[0;32m~/miniconda3/envs/T2M-GPT/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/git/MaskText2Motion/T2M-GPT/utils/eval_trans.py:249\u001b[0m, in \u001b[0;36mevaluation_transformer\u001b[0;34m(out_dir, val_loader, net, trans, logger, writer, nb_iter, best_fid, best_iter, best_div, best_top1, best_top2, best_top3, best_matching, clip_model, eval_wrapper, draw, save, savegif)\u001b[0m\n\u001b[1;32m    245\u001b[0m             matching_score_pred \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m temp_match\n\u001b[1;32m    247\u001b[0m             nb_sample \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m bs\n\u001b[0;32m--> 249\u001b[0m motion_annotation_np \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(motion_annotation_list, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    250\u001b[0m motion_pred_np \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(motion_pred_list, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    251\u001b[0m gt_mu, gt_cov  \u001b[39m=\u001b[39m calculate_activation_statistics(motion_annotation_np)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Named, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradNestedTensor, UNKNOWN_TENSOR_TYPE_ID, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, Autocast, Batched, VmapMode].\n\nCPU: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/build/aten/src/ATen/RegisterCPU.cpp:5925 [kernel]\nCUDA: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/build/aten/src/ATen/RegisterCUDA.cpp:7100 [kernel]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/build/aten/src/ATen/RegisterQuantizedCPU.cpp:641 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradNestedTensor: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nTracer: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/torch/csrc/autograd/generated/TraceType_2.cpp:10525 [kernel]\nAutocast: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/autocast_mode.cpp:254 [kernel]\nBatched: registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1616554786078/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "args.out_dir = './'\n",
    "best_fid, best_iter, best_div, best_top1, best_top2, best_top3, best_matching, writer, logger = \\\n",
    "    eval_trans.evaluation_transformer(args.out_dir, \n",
    "        val_loader, \n",
    "        net, \n",
    "        trans_encoder, \n",
    "        logger, \n",
    "        writer, \n",
    "        0, \n",
    "        best_fid=1000, \n",
    "        best_iter=0, \n",
    "        best_div=100, \n",
    "        best_top1=0, \n",
    "        best_top2=0, \n",
    "        best_top3=0, \n",
    "        best_matching=100, \n",
    "        clip_model=clip_model, \n",
    "        eval_wrapper=eval_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T2M-GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
