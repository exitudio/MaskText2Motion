{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "os.chdir('../')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import models.vqvae as vqvae\n",
    "import utils.losses as losses \n",
    "import options.option_vq as option_vq\n",
    "import utils.utils_model as utils_model\n",
    "from dataset import dataset_VQ, dataset_TM_eval\n",
    "import utils.eval_trans as eval_trans\n",
    "from options.get_eval_option import get_opt\n",
    "from models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from utils.word_vectorizer import WordVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mock:: opt\n",
      "Reading ./checkpoints/kit/Comp_v6_KLD005/opt.txt\n",
      "Loading Evaluation Model Wrapper (Epoch 30) Completed!!\n"
     ]
    }
   ],
   "source": [
    "class Temp:\n",
    "    def __init__(self):\n",
    "        print('mock:: opt')\n",
    "args = Temp()\n",
    "args.dataname = args.dataset_name = 'kit'\n",
    "w_vectorizer = WordVectorizer('./glove', 'our_vab')\n",
    "\n",
    "if args.dataname == 'kit' : \n",
    "    dataset_opt_path = './checkpoints/kit/Comp_v6_KLD005/opt.txt'  \n",
    "    args.nb_joints = 21\n",
    "else :\n",
    "    dataset_opt_path = './checkpoints/t2m/Comp_v6_KLD005/opt.txt'\n",
    "    args.nb_joints = 22\n",
    "wrapper_opt = get_opt(dataset_opt_path, torch.device('cuda'))\n",
    "eval_wrapper = EvaluatorModelWrapper(wrapper_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4888/4888 [00:01<00:00, 3428.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 256\n",
    "args.down_t = 2\n",
    "args.window_size = 64\n",
    "train_loader = dataset_VQ.DATALoader(args.dataname,\n",
    "                                        args.batch_size,\n",
    "                                        window_size=args.window_size,\n",
    "                                        unit_length=2**args.down_t)\n",
    "train_loader_iter = dataset_VQ.cycle(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.nb_code = 512 # 8192 # \n",
    "args.code_dim = 512 # 32 # \n",
    "args.output_emb_width = 512\n",
    "args.down_t = 2\n",
    "args.stride_t = 2\n",
    "args.width = 512\n",
    "args.depth = 3\n",
    "args.dilation_growth_rate = 3\n",
    "args.vq_act = 'relu'\n",
    "args.vq_norm = None\n",
    "\n",
    "args.quantizer = 'ema_reset'\n",
    "args.mu = 0.99\n",
    "net = vqvae.HumanVQVAE(args, ## use args to define different parameters in different quantizers\n",
    "                       args.nb_code,\n",
    "                       args.code_dim,\n",
    "                       args.output_emb_width,\n",
    "                       args.down_t,\n",
    "                       args.stride_t,\n",
    "                       args.width,\n",
    "                       args.depth,\n",
    "                       args.dilation_growth_rate,\n",
    "                       args.vq_act,\n",
    "                       args.vq_norm)\n",
    "# net = torch.nn.DataParallel(net)\n",
    "net.train()\n",
    "net.cuda()\n",
    "\n",
    "args.recons_loss = 'l1_smooth'\n",
    "args.nb_joints\n",
    "Loss = losses.ReConsLoss(args.recons_loss, args.nb_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a torch.Size([2, 251, 64])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "              PrMo-1              [-1, 251, 64]               0\n",
      "            Conv1d-2              [-1, 512, 64]         386,048\n",
      "              ReLU-3              [-1, 512, 64]               0\n",
      "            Conv1d-4              [-1, 512, 32]       1,049,088\n",
      "          Identity-5              [-1, 512, 32]               0\n",
      "              ReLU-6              [-1, 512, 32]               0\n",
      "            Conv1d-7              [-1, 512, 32]         786,944\n",
      "          Identity-8              [-1, 512, 32]               0\n",
      "              ReLU-9              [-1, 512, 32]               0\n",
      "           Conv1d-10              [-1, 512, 32]         262,656\n",
      "   ResConv1DBlock-11              [-1, 512, 32]               0\n",
      "         Identity-12              [-1, 512, 32]               0\n",
      "             ReLU-13              [-1, 512, 32]               0\n",
      "           Conv1d-14              [-1, 512, 32]         786,944\n",
      "         Identity-15              [-1, 512, 32]               0\n",
      "             ReLU-16              [-1, 512, 32]               0\n",
      "           Conv1d-17              [-1, 512, 32]         262,656\n",
      "   ResConv1DBlock-18              [-1, 512, 32]               0\n",
      "         Identity-19              [-1, 512, 32]               0\n",
      "             ReLU-20              [-1, 512, 32]               0\n",
      "           Conv1d-21              [-1, 512, 32]         786,944\n",
      "         Identity-22              [-1, 512, 32]               0\n",
      "             ReLU-23              [-1, 512, 32]               0\n",
      "           Conv1d-24              [-1, 512, 32]         262,656\n",
      "   ResConv1DBlock-25              [-1, 512, 32]               0\n",
      "         Resnet1D-26              [-1, 512, 32]               0\n",
      "           Conv1d-27              [-1, 512, 16]       1,049,088\n",
      "         Identity-28              [-1, 512, 16]               0\n",
      "             ReLU-29              [-1, 512, 16]               0\n",
      "           Conv1d-30              [-1, 512, 16]         786,944\n",
      "         Identity-31              [-1, 512, 16]               0\n",
      "             ReLU-32              [-1, 512, 16]               0\n",
      "           Conv1d-33              [-1, 512, 16]         262,656\n",
      "   ResConv1DBlock-34              [-1, 512, 16]               0\n",
      "         Identity-35              [-1, 512, 16]               0\n",
      "             ReLU-36              [-1, 512, 16]               0\n",
      "           Conv1d-37              [-1, 512, 16]         786,944\n",
      "         Identity-38              [-1, 512, 16]               0\n",
      "             ReLU-39              [-1, 512, 16]               0\n",
      "           Conv1d-40              [-1, 512, 16]         262,656\n",
      "   ResConv1DBlock-41              [-1, 512, 16]               0\n",
      "         Identity-42              [-1, 512, 16]               0\n",
      "             ReLU-43              [-1, 512, 16]               0\n",
      "           Conv1d-44              [-1, 512, 16]         786,944\n",
      "         Identity-45              [-1, 512, 16]               0\n",
      "             ReLU-46              [-1, 512, 16]               0\n",
      "           Conv1d-47              [-1, 512, 16]         262,656\n",
      "   ResConv1DBlock-48              [-1, 512, 16]               0\n",
      "         Resnet1D-49              [-1, 512, 16]               0\n",
      "           Conv1d-50              [-1, 512, 16]         786,944\n",
      "================================================================\n",
      "Total params: 9,568,768\n",
      "Trainable params: 9,568,768\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 5.00\n",
      "Params size (MB): 36.50\n",
      "Estimated Total Size (MB): 41.56\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 62])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### DEBUG \n",
    "# temp = torch.rand(256, 64, 251).cuda()\n",
    "# pred_motion, loss_commit, perplexity = net(temp)\n",
    "# pred_motion, loss_commit, perplexity = net(gt_motion)\n",
    "# print(pred_motion.shape, loss_commit.shape, perplexity.shape)\n",
    "\n",
    "# net = vqvae.HumanVQVAE(args, ## use args to define different parameters in different quantizers\n",
    "#                        args.nb_code,\n",
    "#                        args.code_dim,\n",
    "#                        args.output_emb_width,\n",
    "#                        args.down_t,\n",
    "#                        args.stride_t,\n",
    "#                        args.width,\n",
    "#                        args.depth,\n",
    "#                        args.dilation_growth_rate,\n",
    "#                        args.vq_act,\n",
    "#                        args.vq_norm)\n",
    "# net.cuda()\n",
    "# from torchsummary import summary\n",
    "# summary(net.vqvae.encoder, (251, 64))\n",
    "\n",
    "conv = torch.nn.Conv1d(in_channels=251, out_channels=512, \n",
    "                       kernel_size=3, \n",
    "                       stride=1, \n",
    "                       padding=0)\n",
    "conv(torch.rand(2, 251, 64)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64, 251])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_motion = next(train_loader_iter)\n",
    "gt_motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.commit = 0.02\n",
    "args.loss_vel = 0.5\n",
    "\n",
    "gt_motion = next(train_loader_iter)\n",
    "gt_motion = gt_motion.cuda().float() # (bs, 64, dim)\n",
    "\n",
    "pred_motion, loss_commit, perplexity = net(gt_motion)\n",
    "loss_motion = Loss(pred_motion, gt_motion)\n",
    "loss_vel = Loss.forward_vel(pred_motion, gt_motion)\n",
    "\n",
    "loss = loss_motion + args.commit * loss_commit + args.loss_vel * loss_vel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = dataset_TM_eval.DATALoader(args.dataname, False,\n",
    "                                        32,\n",
    "                                        w_vectorizer,\n",
    "                                        unit_length=2**args.down_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggerWriterMock:\n",
    "    def __init__(self):\n",
    "        self.info\n",
    "    def info(self, *args):\n",
    "        print(*args)\n",
    "    def add_scalar(self, *args):\n",
    "        print(*args)\n",
    "logger = LoggerWriterMock()\n",
    "logger.info('test')\n",
    "writer = LoggerWriterMock()\n",
    "writer.add_scalar('./Test/FID', 'fid', 'nb_iter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.out_dir = './'\n",
    "a = eval_trans.evaluation_vqvae(\n",
    "    args.out_dir, \n",
    "    val_loader, \n",
    "    net, \n",
    "    logger, \n",
    "    writer, \n",
    "    nb_iter = 1, \n",
    "    best_fid = 1, \n",
    "    best_iter = 1, \n",
    "    best_div = 1, \n",
    "    best_top1 = 1, \n",
    "    best_top2 = 1, \n",
    "    best_top3 = 1, \n",
    "    best_matching = 1, \n",
    "    eval_wrapper=eval_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings, pos_one_hots, caption, sent_len, motion, m_length, token, name = next(iter(val_loader))\n",
    "motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T2M-GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
